# -*- coding: utf-8 -*-
"""Chest_Xray CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pbrYKpdJRp6sApZhr6ho7paobx7lnlgz

**import the modules**
"""

import os
import zipfile
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

from google.colab import drive
drive.mount('/content/drive')

base_dir = '/content/drive/My Drive/Datasets/chest_xray'
trainingdir = os.path.join(base_dir,'train')
validation_dir = os.path.join(base_dir,'test')
tnormal = os.path.join(trainingdir,'NORMAL')
tpneumonia = os.path.join(trainingdir,'PNEUMONIA')
vnormal = os.path.join(validation_dir,'NORMAL')
vpneumonia = os.path.join(validation_dir,'PNEUMONIA')

"""**Defining a CNN model 1 with CONV2D layers**
- 4 convolutions and maxpooling layers
- Rectified Linear activation function in all the layers except for the last one
- 2 Dense layers in FC
- Sigmoid activation function in last layers as we're doing  binary classification
- Optimizer - RMSprop
"""

model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),input_shape = (150,150,3),activation = tf.nn.relu),
                                   tf.keras.layers.MaxPooling2D(2,2),
                                   tf.keras.layers.Conv2D(32,(3,3),activation = tf.nn.relu),
                                   tf.keras.layers.MaxPooling2D(2,2),
                                   
                                   tf.keras.layers.Conv2D(64,(3,3),activation = tf.nn.relu),
                                   tf.keras.layers.MaxPooling2D(2,2),
                                   tf.keras.layers.Conv2D(128,(3,3),activation = tf.nn.relu),
                                   tf.keras.layers.MaxPooling2D(2,2),
                                   
                                   tf.keras.layers.Flatten(),
                                   tf.keras.layers.Dense(512,activation = tf.nn.relu),
                                   tf.keras.layers.Dense(128,activation = tf.nn.relu),
                                   tf.keras.layers.Dense(1,activation =tf.nn.sigmoid)])


model.compile(loss = 'binary_crossentropy',
              optimizer=  RMSprop(lr=0.001),
              metrics = ['acc'])

model.summary()

"""**Defining A different CNN model with different architecture**
- Separable CONV2D layers instead of CONV2d
A spatial separable convolution simply divides a kernel into two, smaller kernels. The most common case would be to divide a 3x3 kernel into a 3x1 and 1x3 kernel.
Now, instead of doing one convolution with 9 multiplications, we do two convolutions with 3 multiplications each (6 in total) to achieve the same effect. With less multiplications, computational complexity goes down, and the network is able to run faster.
Added droup out layers to avoid overfitting
- 2 Conv2d layers
- 6 Separable CONV2D layers
- 4 batch normalization
- 4 maxpooling 2D layers
- 3 Dense layers
- rectified linear activation in every layer except for the last one last
- Sigmoid activation in last layer as we are doing binary classification
- Adam optimizer
"""

model2 = tf.keras.Sequential([tf.keras.layers.Conv2D(16,(3,3),input_shape = (150,150,3),activation = tf.nn.relu,padding = 'same'),
                              tf.keras.layers.Conv2D(16,(3,3),activation  = tf.nn.relu,padding = 'same'),
                              tf.keras.layers.BatchNormalization(),
                              tf.keras.layers.MaxPooling2D(2,2),
                              

                              tf.keras.layers.SeparableConv2D(32,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.SeparableConv2D(32,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.BatchNormalization(),
                              tf.keras.layers.MaxPooling2D(2,2),
                              
                             

                              tf.keras.layers.SeparableConv2D(64,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.SeparableConv2D(64,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.BatchNormalization(),
                              tf.keras.layers.MaxPooling2D(2,2),
                              tf.keras.layers.Dropout(rate = 0.2),

                              
                              tf.keras.layers.SeparableConv2D(128,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.SeparableConv2D(128,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.BatchNormalization(),
                              tf.keras.layers.MaxPooling2D(2,2),
                              tf.keras.layers.Dropout(rate = 0.2),
                              

                              tf.keras.layers.SeparableConv2D(256,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.SeparableConv2D(256,(3,3),activation =tf.nn.relu,padding = 'same'),
                              tf.keras.layers.BatchNormalization(),
                              tf.keras.layers.MaxPooling2D(2,2),
                              tf.keras.layers.Dropout(rate = 0.2),

                              tf.keras.layers.Flatten(),

                              tf.keras.layers.Dense(512,activation = tf.nn.relu),
                              tf.keras.layers.Dropout(rate = 0.3),
                              tf.keras.layers.Dense(128,activation = tf.nn.relu),
                              tf.keras.layers.Dropout(rate = 0.4),
                              tf.keras.layers.Dense(64,activation = tf.nn.relu),
                              tf.keras.layers.Dropout(rate = 0.3),
                              

                              tf.keras.layers.Dense(1,activation = tf.nn.sigmoid),
                              
                              ])

model2.compile(loss = 'binary_crossentropy',
               metrics = ['acc'],

               optimizer = 'adam')

model2.summary()

"""**Using Image Augmentation**
Augmenting the image for better accuracy and faster training
**Fitting the model 1**
"""

train_datagen = ImageDataGenerator(rescale=1./255,
                                    rotation_range = 40,
                                    height_shift_range = 0.2,
                                    width_shift_range = 0.2,
                                    zoom_range = 0.2,
                                    horizontal_flip = True,
                                    fill_mode = 'nearest')

validation_datagen = ImageDataGenerator(rescale=1./255,
                                    rotation_range = 40,
                                    height_shift_range = 0.2,
                                    width_shift_range = 0.2,
                                    zoom_range = 0.2,
                                    horizontal_flip = True,
                                    fill_mode = 'nearest')


train_generator = train_datagen.flow_from_directory(trainingdir,
                                                    target_size = (150,150),
                                                    batch_size =20,
                                                    class_mode = 'binary')

validation_generator = validation_datagen.flow_from_directory(validation_dir,
                                                    target_size = (150,150),
                                                    batch_size =20,
                                                    class_mode = 'binary')
from keras.callbacks import ModelCheckpoint, EarlyStopping
# Callbacks
checkpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)
lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')
early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')

history = model.fit_generator(train_generator,
                    epochs = 20,
                    steps_per_epoch = 5126//32,
                    validation_steps = 624//32,
                    validation_data = validation_generator,
                    verbose =1,callbacks = [checkpoint, early])

"""**fitting the model2**"""

history2 = model2.fit_generator(train_generator,
                    epochs = 20,
                    steps_per_epoch  = 5216//32,
                    validation_steps = 624//32,
                    validation_data = validation_generator,
                    verbose =1,callbacks = [checkpoint, early])

"""**Plotting the results (accuracy and validation logs) for the first model**"""

import matplotlib.pyplot as plt

acc =history.history['acc']
val_acc =history.history['val_acc']
loss =history.history['loss']
val_loss =history.history['val_loss']
epooch = range(len(acc))

plt.figure()

plt.plot(epooch, acc, 'b', label='Training accuracy',color = 'red')
plt.plot(epooch, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')

plt.figure()

plt.plot(epooch, loss, 'b', label='Training Loss',color = 'red')
plt.plot(epooch, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

"""**Plotting the results (training and validation loss) for the second model**"""

import matplotlib.pyplot as plt

acc =history2.history['acc']
val_acc =history2.history['val_acc']
loss =history2.history['loss']
val_loss =history2.history['val_loss']
epooch = range(len(acc))

plt.figure()

plt.plot(epooch, acc, 'b', label='Training accuracy',color = 'red')
plt.plot(epooch, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')

plt.figure()

plt.plot(epooch, loss, 'b', label='Training Loss',color = 'red')
plt.plot(epooch, val_loss, 'b', label='Validation Loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()